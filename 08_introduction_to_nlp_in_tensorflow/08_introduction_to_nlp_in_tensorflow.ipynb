{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP Fundamentals in TensorFlow\n",
    "\n",
    "NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n",
    "Another common term for NLP problems is sequence to sequence problems (seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Define a context manager to temporarily add a path to sys.path\n",
    "@contextmanager\n",
    "def temporary_sys_path_append(path):\n",
    "    sys.path.append(path)  # Add the specified path to sys.path\n",
    "    try:\n",
    "        yield  # Allow code within the with-block to execute\n",
    "    finally:\n",
    "        # Ensure the path is removed after exiting the with-block\n",
    "        sys.path.remove(path)\n",
    "\n",
    "# Using the context manager to temporarily add a path to sys.path\n",
    "with temporary_sys_path_append('..'):\n",
    "    # Inside this block, you can import modules located in the added path\n",
    "    from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n",
    "    # Use the function or perform actions with the imported module here\n",
    "\n",
    "# Outside the with-block, the path is no longer in sys.path, limiting the change to the block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a text dataset\n",
    "\n",
    "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in train_df: 7613\n",
      "Total rows in test_df: 3263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el CSV asegurándose de que todos los datos sean cargados\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Verificar el número de filas\n",
    "print(f\"Total rows in train_df: {len(train_df)}\")\n",
    "print(f\"Total rows in test_df: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What dows the test dataframe look like?\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total samples?\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:The last few days of summer are supposed to be the most fun so what's more fun then accidentally burning arm hair while playing w/ a lighter\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:A staged locomotive wreck what could possibly go wrong? http://t.co/Ei9x4H8tHm\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:@gregorysanders @USDOT &amp; the stat of high auto deaths applies to children in a vehicle. I guess they can out run lightrail better than adult\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:And you wonder why he's injured every year https://t.co/XYiwR9JETl\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:Ari's hints and snippets will be the death of me.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5)  # Create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text into numbers\n",
    "\n",
    "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
    "\n",
    "There are a few ways to do this:\n",
    "* Tokenization - direct mapping of token (a token could be a word or a character) to number\n",
    "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization # type: ignore\n",
    "\n",
    "# Use the default TextVectorization parameters\n",
    "text_vectorizer = TextVectorization(max_tokens=None,  # how many words in the vocabulary (all of the different words in the text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None,  # create groups of n-words?\n",
    "                                    output_mode=\"int\",  # how to map tokens to numbers\n",
    "                                    output_sequence_length=None,  # how long do you want your sequences to be\n",
    "                                    pad_to_max_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "max_vocab_length = 10000  # max number of words to have in our vocabulary\n",
    "max_length = 15  # max length our sequences will be (e.g. how many words from a tweet does a model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length,\n",
    "                                    pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "I can't bloody wait!! Sony Sets a Date For Stephen KingÛªs Û÷The Dark TowerÛª #stephenking #thedarktower http://t.co/J9LPdRXCDE  @bdisgusting\n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[   8,   98,  261,  637, 8294, 2710,    3, 1089,   10, 3382,    1,\n",
       "        6400, 1692, 7438, 8094]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()  # get all of the unique words in our training data\n",
    "top_5_words = words_in_vocab[:5]  # most common words\n",
    "bottom_5_words = words_in_vocab[-5:]  # least common words\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") # should be padding, OOV (out of vocabulary), and the most common words in your training data\n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an Embedding layer\n",
    "\n",
    "To make our embedding, we'are going to use TensorFlow's embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "The parameters we care most about for our embedding layer:\n",
    "* `input_dim` = the size of our vocabulary\n",
    "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector of 100 long.\n",
    "* `input_length` = length of the sequences being passed to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gus/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length,  # set input shape\n",
    "                             output_dim=128,  # output shape\n",
    "                             embeddings_initializer=\"uniform\",  # default, initialize randomly\n",
    "                             input_length=max_length)  # how long is each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Get access to the most extensive sources of threat information right out of the box. Then easily add your own internal intelligence. #BHUSA\n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04866168,  0.04592457, -0.04122709, ..., -0.02544199,\n",
       "         -0.0043801 ,  0.0194922 ],\n",
       "        [-0.02011389,  0.02760537,  0.03053558, ..., -0.03898197,\n",
       "         -0.01355717, -0.00320054],\n",
       "        [-0.03453988, -0.00615336,  0.02292676, ...,  0.03956347,\n",
       "          0.0041219 ,  0.02776234],\n",
       "        ...,\n",
       "        [ 0.04665473, -0.00963645,  0.0368516 , ...,  0.007917  ,\n",
       "         -0.02500012,  0.03272524],\n",
       "        [ 0.03176905,  0.03938941,  0.03576026, ..., -0.00668488,\n",
       "          0.03342588,  0.02660043],\n",
       "        [ 0.02859076, -0.02891007,  0.02966419, ..., -0.04621713,\n",
       "         -0.04660917, -0.01070106]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n",
       " array([[ 0.02425699, -0.00273292,  0.02357972, ..., -0.00457346,\n",
       "          0.00609293, -0.00508908],\n",
       "        [-0.03381693, -0.04741812,  0.04547215, ...,  0.02507761,\n",
       "         -0.02553782, -0.00522455],\n",
       "        [-0.04279618, -0.00983522,  0.01600048, ..., -0.0063891 ,\n",
       "         -0.03888643, -0.01203716],\n",
       "        ...,\n",
       "        [ 0.02425699, -0.00273292,  0.02357972, ..., -0.00457346,\n",
       "          0.00609293, -0.00508908],\n",
       "        [-0.01652466, -0.03677965, -0.01801758, ..., -0.0443346 ,\n",
       "          0.02595044, -0.03073645],\n",
       "        [-0.01652466, -0.03677965, -0.01801758, ..., -0.0443346 ,\n",
       "          0.02595044, -0.03073645]], dtype=float32)>,\n",
       " TensorShape([15, 128]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedded version of our random sentence\n",
    "sample_embed[0], sample_embed[0].shape  # check out the shape of our embedded sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a text dataset (running a series of experiments)\n",
    "\n",
    "Now, we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
    "\n",
    "We'll start with a baseline and move on from there.\n",
    "\n",
    "* Model 0: Naive Bayes (baseline), this is from Sklearn ML map: https://scikit-learn.org/stable/\n",
    "* Model 1: Feed-forward neural network (dense model)\n",
    "* Model 2: LSTM model (RNN)\n",
    "* Model 3: GRU model (RNN)\n",
    "* Model 4: Bidirectional-LSTM model (RNN)\n",
    "* Model 5: 1D Convolutional Neural Network (CNN)\n",
    "* Model 6: Tensorflow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
    "* Model 7: Same as model 6 with 10% of training data\n",
    "\n",
    "How are we going to approach all of these?\n",
    "Use the standard steps in modelling with tensorflow:\n",
    "\n",
    "* Create a model\n",
    "* Build a model\n",
    "* Fit a model\n",
    "* Evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Getting a baseline\n",
    "\n",
    "As with all machine learning modelling experiments, it's important to create a baseline model so you've got benchmark for future experiments to build upon.\n",
    "\n",
    "To create our baseline, we'll use Sklearn's Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
    "\n",
    "> 🔑**Note:** It's a common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),  # convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB())  # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences, y=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model on the validation dataset\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "We could evaluate all of our model's predictions with different metrics every time, however, this will be cumbersome and could easily be fixed with a function...\n",
    "\n",
    "Let's create one to compare our model's predictions with the truth labels using the following metrics: \n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                     \"precision\": model_precision * 100,\n",
    "                     \"recall\": model_recall * 100,\n",
    "                     \"f1\": model_f1 * 100}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 79.26509186351706, 'precision': 81.11390004213173, 'recall': 79.26509186351706, 'f1': 78.6218975804955}\n"
     ]
    }
   ],
   "source": [
    "# Get the baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "print(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback (need to create a new one for each model)\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with Functional API\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)  # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs)  # turn the input text into numbers\n",
    "x = embedding(x)  # create an embedding of the numberized inputs\n",
    "x = layers.GlobalAveragePooling1D()(x)  # condense the feature vector for each token to one vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # create the output layer, want binary outputs so use sigmoid activation function\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_1_dense\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_1_dense\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,280,129\u001b[0m (4.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,280,129\u001b[0m (4.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20240719-140945\n",
      "Epoch 1/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6372 - loss: 0.6484 - val_accuracy: 0.7572 - val_loss: 0.5313\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.4625 - val_accuracy: 0.7887 - val_loss: 0.4721\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8610 - loss: 0.3554 - val_accuracy: 0.7900 - val_loss: 0.4605\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8903 - loss: 0.2879 - val_accuracy: 0.7874 - val_loss: 0.4697\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9195 - loss: 0.2356 - val_accuracy: 0.7769 - val_loss: 0.4757\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                    experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7642 - loss: 0.5048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4757358431816101, 0.7769029140472412]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.69028871391076,\n",
       " 'precision': 77.72431692902212,\n",
       " 'recall': 77.69028871391076,\n",
       " 'f1': 77.56776970544695}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions and evaluate\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))  # squeeze removes single dimensions\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of the embedding layer\n",
    "# (these are the numerical representations of each token in the training data, which have been learned for ~5 epochs)\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "print(embed_weights.shape)  # same size as vocab size and embedding_dim (each token is a embedding_dim size vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
    "\n",
    "To do so, Tensorflow has a handy tool called projector: https://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding files (we got this from TensorFlow documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📖**Resources:** If you'd like to know more about embeddings. i'd encourage you to check out:\n",
    "* Jay Alammar's visualized word2vec post: https://jalammar.github.io/illustrated-word2vec/\n",
    "* Tensorflow's Word Embeddings guide: https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "\n",
    "RNN's are useful for sequence data.\n",
    "\n",
    "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM\n",
    "\n",
    "LSTM = long short term memory (one of the most popular LSTM cells)\n",
    "\n",
    "```\n",
    "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM model\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)  # return sequences set to True for stacking layers\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2_LSTM\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2_LSTM\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,362,497</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,362,497\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,362,497</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,362,497\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a summary of the model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20240719-141004\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 14:10:06.172826: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9129 - loss: 0.2829 - val_accuracy: 0.7782 - val_loss: 0.6017\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9442 - loss: 0.1636 - val_accuracy: 0.7822 - val_loss: 0.6524\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9566 - loss: 0.1171 - val_accuracy: 0.7782 - val_loss: 0.8436\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9617 - loss: 0.1033 - val_accuracy: 0.7651 - val_loss: 0.7614\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9633 - loss: 0.0839 - val_accuracy: 0.7703 - val_loss: 0.9613\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 77.11671866902317,\n",
       " 'recall': 77.03412073490814,\n",
       " 'f1': 76.86901866564683}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with our LSTM model\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_results = calculate_results(val_labels, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 81.11390004213173,\n",
       " 'recall': 79.26509186351706,\n",
       " 'f1': 78.6218975804955}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRU\n",
    "\n",
    "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
    "\n",
    "The GRU cell has similar features to an LSTM cell but has less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an RNN using the GRU cell\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GRU(64,return_sequences=True)(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_3_GRU\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_3_GRU\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,350,337</span> (5.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,350,337\u001b[0m (5.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,350,337</span> (5.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,350,337\u001b[0m (5.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comnpile the model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20240719-141037\n",
      "Epoch 1/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9433 - loss: 0.2568 - val_accuracy: 0.7756 - val_loss: 0.7040\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9638 - loss: 0.0986 - val_accuracy: 0.7677 - val_loss: 0.7319\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9710 - loss: 0.0700 - val_accuracy: 0.7664 - val_loss: 0.9386\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9721 - loss: 0.0594 - val_accuracy: 0.7612 - val_loss: 1.2340\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9744 - loss: 0.0559 - val_accuracy: 0.7677 - val_loss: 1.1098\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 76.74723453090631,\n",
       " 'recall': 76.77165354330708,\n",
       " 'f1': 76.68863186407148}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_results = calculate_results(val_labels, model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectional RNN\n",
    "\n",
    "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes from right to left as well as left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an RNN using the Bidirectional RNN\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_4_Bidirectional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_4_Bidirectional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,378,945</span> (5.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,378,945\u001b[0m (5.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,378,945</span> (5.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,378,945\u001b[0m (5.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_Bidirectional/20240719-141109\n",
      "Epoch 1/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9290 - loss: 0.2378 - val_accuracy: 0.7690 - val_loss: 0.8012\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9792 - loss: 0.0521 - val_accuracy: 0.7664 - val_loss: 0.9257\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9815 - loss: 0.0446 - val_accuracy: 0.7625 - val_loss: 1.1611\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.9765 - loss: 0.0471 - val_accuracy: 0.7625 - val_loss: 1.2730\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9843 - loss: 0.0366 - val_accuracy: 0.7638 - val_loss: 1.2114\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_4_Bidirectional\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.37795275590551,\n",
       " 'precision': 76.39261289761721,\n",
       " 'recall': 76.37795275590551,\n",
       " 'f1': 76.24822674694383}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks for text (and other types of sequences)\n",
    "\n",
    "We've used CNNs for images but images are typically 2D (height x width)... however, our text data is 1D.\n",
    "\n",
    "Previously we've Conv2D for our images data but bow we're going to use Conv1D.\n",
    "\n",
    "The typical structure of a Conv1D model for sequences (in our case, text):\n",
    "\n",
    "```\n",
    "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs (class probabilities)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1721409103.859328   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.904022   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.910918   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.925437   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.932949   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.939466   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.946474   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.953894   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.960888   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.967747   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.974117   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.981555   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.987621   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409103.995310   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.002171   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.009269   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.015954   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.021977   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.028860   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.036831   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.044080   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.049750   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.056999   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.063775   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.071448   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.078399   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.085478   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.092061   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.099050   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.104683   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.107382   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.112679   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.118973   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.133623   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1721409104.140391   85582 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out our embedding layer, Conv1D layer and max pooling\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))  # turn target sentence into embedding\n",
    "conv1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\", padding=\"valid\")  # convolve over target sequence 5 words at a time\n",
    "conv1d_output = conv1d(embedding_test)  # pass the embedded sequence to the convolutional layer\n",
    "max_pool = layers.GlobalMaxPool1D()  # get the most important features\n",
    "max_pool_output = max_pool(conv1d_output)  # reduce the dimensions of the data\n",
    "embedding_test.shape, conv1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_5_Conv1D\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_5_Conv1D\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m41,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,321,089</span> (5.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,321,089\u001b[0m (5.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,321,089</span> (5.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,321,089\u001b[0m (5.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 1D convolutional model to process sequences\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary of the model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20240719-141205\n",
      "Epoch 1/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9825 - loss: 0.0432 - val_accuracy: 0.7677 - val_loss: 1.1639\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9829 - loss: 0.0399 - val_accuracy: 0.7585 - val_loss: 1.2559\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0388 - val_accuracy: 0.7677 - val_loss: 1.2141\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9808 - loss: 0.0396 - val_accuracy: 0.7677 - val_loss: 1.2108\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0384 - val_accuracy: 0.7625 - val_loss: 1.2731\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_5_Conv1D\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.24671916010499,\n",
       " 'precision': 76.29611993882945,\n",
       " 'recall': 76.24671916010499,\n",
       " 'f1': 76.08791530897156}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_results = calculate_results(val_labels, model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: Tensorflow Hub Pretrained Sentence Encoder\n",
    "\n",
    "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03133018 -0.06338634 -0.01607499 ... -0.03242779 -0.04575738\n",
      "   0.05370456]\n",
      " [ 0.0508086  -0.01652431  0.01573778 ...  0.00976658  0.03170119\n",
      "   0.01788118]], shape=(2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub \n",
    "\n",
    "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\")\n",
    "embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"])\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras layer using the USE pretrained layer from TensorFlow Hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fixing keras 3.x.x bug\n",
    "import tf_keras as keras\n",
    "\n",
    "# Create model using the Sequential API\n",
    "model_6 = keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary of the model\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 35ms/step - loss: 0.5087 - accuracy: 0.7774 - val_loss: 0.4481 - val_accuracy: 0.7953\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4158 - accuracy: 0.8162 - val_loss: 0.4385 - val_accuracy: 0.8123\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4014 - accuracy: 0.8228 - val_loss: 0.4372 - val_accuracy: 0.8097\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.3931 - accuracy: 0.8263 - val_loss: 0.4293 - val_accuracy: 0.8150\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.3859 - accuracy: 0.8321 - val_loss: 0.4271 - val_accuracy: 0.8189\n"
     ]
    }
   ],
   "source": [
    "# Train a model with the USE pretrained layer\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels)#,\n",
    "                              #callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_6_USE\")]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.88976377952756,\n",
       " 'precision': 81.98576982951774,\n",
       " 'recall': 81.88976377952756,\n",
       " 'f1': 81.79030717265692}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 81.11390004213173,\n",
       " 'recall': 79.26509186351706,\n",
       " 'f1': 78.6218975804955}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model results\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: TF Hub Pretrained USE but with 10% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 685)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create subsets of 10% of the training data\n",
    "train_sentences_10_percent = train_sentences[:int(0.1 * len(train_sentences))]\n",
    "train_labels_10_percent = train_labels[:int(0.1 * len(train_labels))]\n",
    "len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data\n",
    "pd.Series(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone model_6 but reset the weights\n",
    "model_7 = keras.models.clone_model(model_6)\n",
    "\n",
    "# Compile the model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 67ms/step - loss: 0.6729 - accuracy: 0.6774 - val_loss: 0.6499 - val_accuracy: 0.7598\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.6039 - accuracy: 0.8131 - val_loss: 0.5918 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 0.5288 - accuracy: 0.8175 - val_loss: 0.5378 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.4655 - accuracy: 0.8277 - val_loss: 0.5046 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 0.4226 - accuracy: 0.8307 - val_loss: 0.4884 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_7_history = model_7.fit(train_sentences_10_percent,\n",
    "                              train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              #callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_7_USE_10_percent\")]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 78.08713829501961,\n",
       " 'recall': 77.95275590551181,\n",
       " 'f1': 77.776991732408}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.10236220472441,\n",
       " 'precision': 81.1513075854206,\n",
       " 'recall': 81.10236220472441,\n",
       " 'f1': 81.0153774429212}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model results 6 and 7\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the performance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>81.113900</td>\n",
       "      <td>79.265092</td>\n",
       "      <td>78.621898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>77.690289</td>\n",
       "      <td>77.724317</td>\n",
       "      <td>77.690289</td>\n",
       "      <td>77.567770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>77.116719</td>\n",
       "      <td>77.034121</td>\n",
       "      <td>76.869019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>76.771654</td>\n",
       "      <td>76.747235</td>\n",
       "      <td>76.771654</td>\n",
       "      <td>76.688632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>76.377953</td>\n",
       "      <td>76.392613</td>\n",
       "      <td>76.377953</td>\n",
       "      <td>76.248227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>76.246719</td>\n",
       "      <td>76.296120</td>\n",
       "      <td>76.246719</td>\n",
       "      <td>76.087915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>81.758530</td>\n",
       "      <td>81.807264</td>\n",
       "      <td>81.758530</td>\n",
       "      <td>81.678452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>78.087138</td>\n",
       "      <td>77.952756</td>\n",
       "      <td>77.776992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  precision     recall         f1\n",
       "baseline  79.265092  81.113900  79.265092  78.621898\n",
       "model_1   77.690289  77.724317  77.690289  77.567770\n",
       "model_2   77.034121  77.116719  77.034121  76.869019\n",
       "model_3   76.771654  76.747235  76.771654  76.688632\n",
       "model_4   76.377953  76.392613  76.377953  76.248227\n",
       "model_5   76.246719  76.296120  76.246719  76.087915\n",
       "model_6   81.758530  81.807264  81.758530  81.678452\n",
       "model_7   77.952756  78.087138  77.952756  77.776992"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"model_1\": model_1_results,\n",
    "                                  \"model_2\": model_2_results,\n",
    "                                  \"model_3\": model_3_results,\n",
    "                                  \"model_4\": model_4_results,\n",
    "                                  \"model_5\": model_5_results,\n",
    "                                  \"model_6\": model_6_results,\n",
    "                                  \"model_7\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f198f343b20>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading a trained model\n",
    "\n",
    "There are two main formats to save a model to in TensorFlow:\n",
    "1. The HDF5 format\n",
    "2. The `SaveModel` format (this is the default when using TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gus/.local/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6_USE.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required for HDF5 format)\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "loaded_model_6 = keras.models.load_model(\"model_6_USE.h5\",\n",
    "                                         custom_objects={\"KerasLayer\": hub.KerasLayer}) # required for loading in the Hub layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 39ms/step - loss: 0.4262 - accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4261632263660431, 0.817585289478302]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_USE_10_percent_SavedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_USE_10_percent_SavedModel/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model 7 to SavedModel format (default)\n",
    "model_6.save(\"model_6_USE_10_percent_SavedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a model from SavedModel format\n",
    "loaded_model_6 = keras.models.load_model(\"model_6_USE_10_percent_SavedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 40ms/step - loss: 0.4262 - accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42616337537765503, 0.817585289478302]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the loaded SavedModel format\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most wrong examples\n",
    "\n",
    "* If our best model still isn't perfect, what examples is it getting wrong?\n",
    "* And of these wrong examples which ones is it getting *most* wrong (those will prediction probabilities closet to the opposite class)\n",
    "\n",
    "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.99 (really close to 1) and viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.794939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.212385\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.832702\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.990789\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.179733\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.794939"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with validation sentences and best performing model predictions\n",
    "val_df = pd.DataFrame({\"text\": val_sentences, \"target\": val_labels, \"pred\": model_6_preds, \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "1    FedEx no longer to transport bioterror germs i...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.941121  \n",
       "759   0.923932  \n",
       "628   0.873802  \n",
       "49    0.869682  \n",
       "209   0.866447  \n",
       "393   0.866147  \n",
       "109   0.862897  \n",
       "1     0.832702  \n",
       "251   0.827445  \n",
       "119   0.826077  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10] # false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>@DavidVonderhaar At least you were sincere ??</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>going to redo my nails and watch behind the sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Lucas Duda is Ghost Rider. Not the Nic Cage ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>@willienelson We need help! Horses will die!Pl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>You can never escape me. Bullets don't harm me...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "536      @DavidVonderhaar At least you were sincere ??       1   0.0   \n",
       "221  going to redo my nails and watch behind the sc...       1   0.0   \n",
       "294  Lucas Duda is Ghost Rider. Not the Nic Cage ve...       1   0.0   \n",
       "408  @willienelson We need help! Horses will die!Pl...       1   0.0   \n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "59   You can never escape me. Bullets don't harm me...       1   0.0   \n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "\n",
       "     pred_prob  \n",
       "536   0.064655  \n",
       "221   0.062809  \n",
       "294   0.061039  \n",
       "408   0.053200  \n",
       "411   0.050239  \n",
       "59    0.048715  \n",
       "233   0.048320  \n",
       "244   0.038131  \n",
       "38    0.033785  \n",
       "23    0.027525  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wrong.tail(10) # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1, Prob: 0.9411214590072632\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.9239324331283569\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8738017082214355\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8696823716163635\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8664467334747314\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8661472797393799\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8628971576690674\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8327018022537231\n",
      "Text:\n",
      "FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8274450898170471\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8260769248008728\n",
      "Text:\n",
      "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:10].itertuples():\n",
    "    _, text, target, pred, pred_prob = row\n",
    "    print(f\"Target: {target}, Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0, Prob: 0.06465517729520798\n",
      "Text:\n",
      "@DavidVonderhaar At least you were sincere ??\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06280933320522308\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06103905290365219\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.05319954454898834\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.050239257514476776\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.04871534928679466\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.04832005128264427\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.038130983710289\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.033785056322813034\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.02752511203289032\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false negatives (model predicted 0 when should've been 1)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "    _, text, target, pred, pred_prob = row\n",
    "    print(f\"Target: {target}, Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step\n",
      "Pred: 1, Prob: 0.9686403870582581\n",
      "Text:\n",
      "Severe Thunderstorm Warnings have been cancelled in central Oklahoma. Still expect 50 mph winds penny sized hail\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Pred: 0, Prob: 0.37172064185142517\n",
      "Text:\n",
      "Watch Steaks Being Grilled Over Molten Hot Lava http://t.co/yxns3IiXjv http://t.co/lcM66dHn1l\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Pred: 1, Prob: 0.6709924340248108\n",
      "Text:\n",
      "@JoeNBC IRAN: NO SNCTIONS INCL MILTARY$150BILNO INSPCTKPS HOSTAGESTHROSW ISRAEL TO GUTRKPS NUKE SITES U.S HLPS W/NUKES GET 'ZERO!'\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Pred: 0, Prob: 0.10496115684509277\n",
      "Text:\n",
      "@jemmaswans i needed such a breather today oh my god i went on lunch and collapsed like a sack of bones in my car\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "Pred: 0, Prob: 0.33495721220970154\n",
      "Text:\n",
      "S3XLEAK!!!\n",
      "Ph0tos of 19yrs old Ash@wo lady in Festac town from Delta exp0sed on BBM 5 leaked pictures... http://t.co/lUm4l65alz\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Pred: 0, Prob: 0.17666469514369965\n",
      "Text:\n",
      "the Burning Legion has returned\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Pred: 0, Prob: 0.10061614960432053\n",
      "Text:\n",
      "We need to stop paying attention to @drizzy body bagging @Meekmill and worry bout what happen to #SandraBland\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Pred: 1, Prob: 0.6720342636108398\n",
      "Text:\n",
      "A Dog Was Abandoned In A Thunderstorm. But Then A Neighbor Steps Up And Does THIS http://t.co/iR3OXEH7id\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Pred: 1, Prob: 0.903147280216217\n",
      "Text:\n",
      "It doesn't get any closer. Heavy rain just barely missed @TontitownGrape festival but lightning TOO CLOSE #TGF2015 http://t.co/d9PQIXaTX6\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Pred: 0, Prob: 0.09556389600038528\n",
      "Text:\n",
      "@exoticengram @TheRasputin That Raspy is so cool and he has already figured out TTK's battle shit.\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset and visualizing them\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "    pred_prob = tf.squeeze(model_6.predict([test_sample]))\n",
    "    pred = tf.round(pred_prob)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{test_sample}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Severe Thunderstorm Warnings have been cancelled in central Oklahoma. Still expect 50 mph winds penny sized hail', 'Watch Steaks Being Grilled Over Molten Hot Lava http://t.co/yxns3IiXjv http://t.co/lcM66dHn1l', \"@JoeNBC IRAN: NO SNCTIONS INCL MILTARY$150BILNO INSPCTKPS HOSTAGESTHROSW ISRAEL TO GUTRKPS NUKE SITES U.S HLPS W/NUKES GET 'ZERO!'\", '@jemmaswans i needed such a breather today oh my god i went on lunch and collapsed like a sack of bones in my car', 'S3XLEAK!!!\\nPh0tos of 19yrs old Ash@wo lady in Festac town from Delta exp0sed on BBM 5 leaked pictures... http://t.co/lUm4l65alz', 'the Burning Legion has returned', 'We need to stop paying attention to @drizzy body bagging @Meekmill and worry bout what happen to #SandraBland', 'A Dog Was Abandoned In A Thunderstorm. But Then A Neighbor Steps Up And Does THIS http://t.co/iR3OXEH7id', \"It doesn't get any closer. Heavy rain just barely missed @TontitownGrape festival but lightning TOO CLOSE #TGF2015 http://t.co/d9PQIXaTX6\", \"@exoticengram @TheRasputin That Raspy is so cool and he has already figured out TTK's battle shit.\"]\n"
     ]
    }
   ],
   "source": [
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "https://github.com/mrdbourke/tensorflow-deep-learning#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_1, Model_2, Model_5\n",
    "\n",
    "Rebuild, compile and train model_1, model_2 and model_5 using the Keras Sequential API instead of the Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6598 - loss: 0.6462 - val_accuracy: 0.7546 - val_loss: 0.5332\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 0.4598 - val_accuracy: 0.7835 - val_loss: 0.4720\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8596 - loss: 0.3513 - val_accuracy: 0.7953 - val_loss: 0.4557\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8945 - loss: 0.2777 - val_accuracy: 0.7861 - val_loss: 0.4612\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9090 - loss: 0.2450 - val_accuracy: 0.7861 - val_loss: 0.4796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8007701e10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild model_1\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    text_vectorizer,\n",
    "    embedding,\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_1_dense\")\n",
    "\n",
    "# Compile model_1\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(train_sentences,\n",
    "            train_labels,\n",
    "            epochs=5,\n",
    "            validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 11:01:22.180654: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.9171 - loss: 0.2777 - val_accuracy: 0.7861 - val_loss: 0.5084\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9472 - loss: 0.1544 - val_accuracy: 0.7848 - val_loss: 0.7259\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9467 - loss: 0.1410 - val_accuracy: 0.7795 - val_loss: 0.6969\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9601 - loss: 0.1118 - val_accuracy: 0.7769 - val_loss: 0.8182\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9713 - loss: 0.0743 - val_accuracy: 0.7690 - val_loss: 1.0474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7f9c1b0940>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild model 2\n",
    "model_2 = tf.keras.Sequential([\n",
    "    text_vectorizer,\n",
    "    embedding,\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_2_LSTM\")\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_2.fit(train_sentences,\n",
    "            train_labels,\n",
    "            epochs=5,\n",
    "            validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9375 - loss: 0.1800 - val_accuracy: 0.7703 - val_loss: 0.9186\n",
      "Epoch 2/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9797 - loss: 0.0621 - val_accuracy: 0.7612 - val_loss: 1.0060\n",
      "Epoch 3/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9813 - loss: 0.0466 - val_accuracy: 0.7572 - val_loss: 1.0591\n",
      "Epoch 4/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9767 - loss: 0.0518 - val_accuracy: 0.7572 - val_loss: 1.0955\n",
      "Epoch 5/5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9808 - loss: 0.0466 - val_accuracy: 0.7598 - val_loss: 1.1439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7f603a9600>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild model 5\n",
    "model_5 = tf.keras.Sequential([\n",
    "    text_vectorizer,\n",
    "    embedding,\n",
    "    layers.Conv1D(64, kernel_size=5, activation=\"relu\"),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_5.fit(train_sentences,\n",
    "            train_labels,\n",
    "            epochs=5,\n",
    "            validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline with 10%\n",
    "Retrain the baseline model with 10% of the training data. How does perform compared to the Universal Sentence Encoder model with 10% of the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 70.21%\n"
     ]
    }
   ],
   "source": [
    "# Retrain baseline model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_0_retrained = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0_retrained.fit(train_sentences_10_percent, train_labels_10_percent)\n",
    "\n",
    "# Evaluate the retrained baseline model\n",
    "baseline_score_retrained = model_0_retrained.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score_retrained*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model on the validation dataset\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tunning TF Hub Universal\n",
    "Try fine-tuning the TF Hub Universal Sentence Encoder model by setting training=True when instantiating it as a Keras layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TF Hub USE\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "sentence_encoder_layer_true = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=True, # fine-tune USE\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing keras 3.x.x bug\n",
    "import tf_keras as keras\n",
    "\n",
    "# Rebuild model_6\n",
    "model_6_retrained = keras.Sequential([\n",
    "    sentence_encoder_layer_true,\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model\n",
    "model_6_retrained.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_6_retrained.fit(train_sentences_10_percent,\n",
    "                      train_labels_10_percent,\n",
    "                      epochs=5,\n",
    "                      batch_size=16,  # Try reducing the batch size\n",
    "                      validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this makes no sense, no GPU can support the memory allocation needed for the model. But I can make a model differently to fine-tunning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721746236.408436   29442 service.cc:146] XLA service 0x7f7fdd8d9aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721746236.408486   29442 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2024-07-23 11:50:36.414232: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 11:50:36.443419: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8904\n",
      "I0000 00:00:1721746236.540931   29442 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 19s 34ms/step - loss: 0.4776 - accuracy: 0.7794 - val_loss: 0.4602 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.4183 - accuracy: 0.8175 - val_loss: 0.4398 - val_accuracy: 0.8084\n",
      "Epoch 3/5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.3976 - accuracy: 0.8311 - val_loss: 0.4691 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.3677 - accuracy: 0.8390 - val_loss: 0.4724 - val_accuracy: 0.8031\n",
      "Epoch 5/5\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.3354 - accuracy: 0.8626 - val_loss: 0.4588 - val_accuracy: 0.8097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f7fcea8cfa0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild model_6\n",
    "import tf_keras as keras\n",
    "\n",
    "model_6_retrained = keras.Sequential([\n",
    "    sentence_encoder_layer_true,\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# trainable=True\n",
    "for layer in model_6_retrained.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Freeze all layers except for the last 5\n",
    "for layer in model_6_retrained.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model_6_retrained.compile(loss=\"binary_crossentropy\",\n",
    "                          optimizer=keras.optimizers.Adam(),\n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_6_retrained.fit(train_sentences,\n",
    "                      train_labels,\n",
    "                      epochs=5,\n",
    "                      batch_size=16,  # Try reducing the batch size\n",
    "                      validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole training set\n",
    "Retrain the best model you've got so far on the whole training set (no validation split). Then use this trained model to make predictions on the test dataset and format the predictions into the same format as the sample_submission.csv file from Kaggle (see the Files tab in Colab for what the sample_submission.csv file looks like). Once you've done this, make a submission to the Kaggle competition, how did your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "238/238 [==============================] - 8s 29ms/step - loss: 0.5053 - accuracy: 0.7725\n",
      "Epoch 2/5\n",
      "238/238 [==============================] - 7s 31ms/step - loss: 0.4147 - accuracy: 0.8164\n",
      "Epoch 3/5\n",
      "238/238 [==============================] - 7s 31ms/step - loss: 0.4010 - accuracy: 0.8215\n",
      "Epoch 4/5\n",
      "238/238 [==============================] - 8s 32ms/step - loss: 0.3926 - accuracy: 0.8261\n",
      "Epoch 5/5\n",
      "238/238 [==============================] - 7s 31ms/step - loss: 0.3863 - accuracy: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f7fbecee080>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain model_6 on full data\n",
    "# Fixing keras 3.x.x bug\n",
    "import tf_keras as keras\n",
    "\n",
    "# Create model using the Sequential API\n",
    "model_6 = keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_6.fit(train_df_shuffled[\"text\"].to_numpy(),\n",
    "            train_df_shuffled[\"target\"].to_numpy(),\n",
    "            epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0     1.0\n",
       "1   2     1.0\n",
       "2   3     1.0\n",
       "3   9     1.0\n",
       "4  11     1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_6_pred_probs = model_6.predict(test_df[\"text\"].to_numpy())\n",
    "\n",
    "# Create DataFrame with test sentences and model predictions\n",
    "test_df[\"target\"] = tf.squeeze(tf.round(model_6_pred_probs)).numpy()\n",
    "\n",
    "# delete keyword and location columns\n",
    "test_df = test_df.drop([\"keyword\", \"location\", \"text\"], axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in test_df: 3263\n"
     ]
    }
   ],
   "source": [
    "# Asegurarse de que todas las filas están siendo consideradas\n",
    "print(f\"Total rows in test_df: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  target\n",
      "0   0       1\n",
      "1   2       1\n",
      "2   3       1\n",
      "3   9       1\n",
      "4  11       1\n"
     ]
    }
   ],
   "source": [
    "# Create a submission DataFrame\n",
    "submission_df = test_df[[\"id\", \"target\"]]\n",
    "submission_df[\"target\"] = submission_df[\"target\"].astype(int)\n",
    "\n",
    "# Create a submission CSV file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "Make a confusion matrix with the best performing model's predictions on the validation set and the validation ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(val_labels, model_6_preds)\n",
    "\n",
    "# Turn the confusion matrix into a DataFrame\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=[\"non-disaster\", \"disaster\"],\n",
    "                     columns=[\"non-disaster\", \"disaster\"])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df, annot=True, cbar=False, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
