{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we are going to cover some of the most fundemental concepts of tensors using Tensorflow\n",
    "\n",
    "## More specifically, we are going to cover:\n",
    "- Introducing to tensors\n",
    "- Getting information from tensors\n",
    "- Manipulating tensors\n",
    "- Tensors & NumPy\n",
    "- Using @tf.function (a way to speed up your regular Python functions)\n",
    "- Using GPUs with TensorFlow (or TPUs)\n",
    "- Exercise to try for myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:18:11.916489: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-17 17:18:12.050746: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-17 17:18:12.840318: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 17:18:12.840443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 17:18:12.970663: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 17:18:13.252410: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-17 17:18:13.257786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 17:18:15.133297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors with tf.constant()\n",
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of dimensions of the tensor (ndim stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector\n",
    "vector = tf.constant([10,10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimensions of my vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix (has more than 1 dimension)\n",
    "matrix = tf.constant([[10,7],\n",
    "                     [7,10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create another matrix\n",
    "matrix_2 = tf.constant([[10.,7.],\n",
    "                        [3.,2.],\n",
    "                        [8.,9.]], dtype=tf.float16) #specify the data type with dtype parameter\n",
    "matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                       [4, 5, 6]],\n",
    "                       [[7, 8, 9],\n",
    "                        [10, 11, 12]],\n",
    "                        [[13, 14, 15],\n",
    "                         [16, 17 ,18]]])\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What i have created so far\n",
    "- Scalar: a single number\n",
    "- Vector: a number with direction\n",
    "- Matrix: a 2-dimensional array of numbers\n",
    "- Tensor: a n-dimensional array of numbers (where n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors with `tf.variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the same tensor with tf.variable() as above\n",
    "changeable_tensor = tf.Variable([10, 7])\n",
    "unchageable_tensor = tf.constant([10, 7])\n",
    "changeable_tensor, unchageable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try change one of the elements in our changeable tensor\n",
    "changeable_tensor[0].assign(7)\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîë **Note:** Rarely in practice will you need to decide wheter to use `tf.constant` or `tf.Variable` to create tensors, as TensorFlow does this for you. However, if in doubt, use `tf.constant` and change it later if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating random tensors\n",
    "\n",
    "Random tensors are tensors of some arbitrary size which contain random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 2 ramdons tensors (but the same)\n",
    "random_1 = tf.random.Generator.from_seed(42) # set seed for reproducibility\n",
    "random_1 = random_1.normal(shape = (3,2))\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape = (3,2))\n",
    "\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the order in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 2,  5],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle a tensor (valuable for when you want to shuffle your data so the inherent order does not effect learning)\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "#shuffle my no-shufled tensor\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ†Ô∏è **Exercise:** Practice on random seed generation and write 5 random tensors and shuffle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix Tensor 1: [0.3528825  0.6645621  0.44100678]\n",
      "Mix Tensor 2: [0.01738465 0.62854624 0.7413678 ]\n",
      "Mix Tensor 3: [0.803156   0.37054038 0.49777734]\n",
      "Mix Tensor 4: [0.43555546 0.49674678 0.52486527]\n",
      "Mix Tensor 5: [0.81674874 0.2046014  0.82478166]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    tensor = tf.random.uniform(shape=[3])\n",
    "    shuffled_tensor = tf.random.shuffle(tensor)\n",
    "    print(f\"Mix Tensor {i}: {shuffled_tensor.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All shuffled tensors will be reproducible across script executions. The shuffle sequence will be the same every time you run the script. This is because the global seed sets a common starting point for all random operations, ensuring consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operation-Level Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix Tensor 1: [0.63992536 0.81787777 0.15012848]\n",
      "Mix Tensor 2: [0.20244026 0.4828781  0.22027123]\n",
      "Mix Tensor 3: [0.06012475 0.02529657 0.01177216]\n",
      "Mix Tensor 4: [0.8162794  0.95071614 0.26013935]\n",
      "Mix Tensor 5: [0.9129821  0.33574915 0.61781967]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    tensor = tf.random.uniform(shape=[3], seed=1)\n",
    "    shuffled_tensor = tf.random.shuffle(tensor)\n",
    "    print(f\"Mix Tensor {i}: {shuffled_tensor.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shuffle of each tensor depends on the specific seed passed to the operation. Without a global seed, the results will not be reproducible across different script executions. This is because the operation-level seed controls the randomness of that particular operation, but without a global reference point, each run starts with a different internal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Seed and Operation-Level Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix Tensor 1: [0.63992536 0.81787777 0.15012848]\n",
      "Mix Tensor 2: [0.22027123 0.4828781  0.20244026]\n",
      "Mix Tensor 3: [0.06012475 0.02529657 0.01177216]\n",
      "Mix Tensor 4: [0.95071614 0.26013935 0.8162794 ]\n",
      "Mix Tensor 5: [0.61781967 0.33574915 0.9129821 ]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    tensor = tf.random.uniform(shape=[3], seed=1)\n",
    "    shuffled_tensor = tf.random.shuffle(tensor)\n",
    "    print(f\"Mix Tensor {i}: {shuffled_tensor.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global seed ensures reproducibility across executions, while the operation-level seed controls the specific shuffle in each operation. This combination allows for consistent, repeatable results across script runs (thanks to the global seed) but with controlled variation in each operation (due to the operation-level seed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "tf.ones([10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeroes\n",
    "tf.zeros([10,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn NumPy arrays into tensors\n",
    "\n",
    "The main difference between Numpy arrays and TensorFlow tensors can be run on a GPU (much faster for numerical computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn NumPy arrays into tensors\n",
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32) # create a NumPy array between 1 and 25\n",
    "numpy_A\n",
    "\n",
    "# X = tf.constant(some_matrix) capital for matrix or tensor\n",
    "# y = tf.constant(vector) non-capital for vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15, 16],\n",
       "         [17, 18, 19, 20],\n",
       "         [21, 22, 23, 24]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24], dtype=int32)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant(numpy_A, shape=(2, 3, 4))\n",
    "B = tf.constant(numpy_A)\n",
    "A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "- **Shape:** The length of each of the dimensions of the tensor `tensor.shape`\n",
    "\n",
    "- **Rank:** The number of tensor dimension `tensor.ndim`\n",
    "\n",
    "- **Axis or dimension:** A particular dimension of a tensor `tensor[0]` `tensor[:, 1]`\n",
    "\n",
    "- **Size:** The total number of items in the tensor `tf.size(tensor)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 tensor\n",
    "rank_4_tensor = tf.zeros(shape=[2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element:  <dtype: 'float32'>\n",
      "Number of dimensions (rank):  4\n",
      "Shape of tensor:  (2, 3, 4, 5)\n",
      "Elements along the 0 axis:  2\n",
      "Elements along the last axis:  5\n",
      "Total number of elements in my tensor:  tf.Tensor(120, shape=(), dtype=int32)\n",
      "Total number of elements in my tensor:  120\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of our tensor\n",
    "print(\"Datatype of every element: \", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank): \", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor: \", rank_4_tensor.shape)\n",
    "print(\"Elements along the 0 axis: \", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis: \", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements in my tensor: \", tf.size(rank_4_tensor))\n",
    "print(\"Total number of elements in my tensor: \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing tensors\n",
    "\n",
    "Tensors can be indexed just like Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 2 elements of each dimension\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first element from each dimension from each index except for the final one\n",
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2]), 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[2, 3],\n",
    "                             [10, 7]])\n",
    "rank_2_tensor.shape, rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 7], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last item of each row of my rank 2 tensor\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[ 2],\n",
       "        [ 3]],\n",
       "\n",
       "       [[10],\n",
       "        [ 7]]], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in extra dimension to the rank 2 tensor\n",
    "rank_3_tensor = rank_2_tensor[...,tf.newaxis]\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[ 2],\n",
       "        [ 3]],\n",
       "\n",
       "       [[10],\n",
       "        [ 7]]], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative to tf.newaxis\n",
    "tf.expand_dims(rank_2_tensor, axis=-1) # -1 means expand the final axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[ 2,  3],\n",
       "        [10,  7]]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the 0-axis\n",
    "tf.expand_dims(rank_2_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)\n",
    "**Basic operations** `+`,`-`,`*`,`/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add values to a tensor using the addittion operator\n",
    "tensor = tf.constant([[10, 7], \n",
    "                      [3, 4]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication also works\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substraction\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use tensorflow built-in function too\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is unchaged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix multiplication**\n",
    "\n",
    "In machine learning, matrix multiplication is one of the most common tensor operations.\n",
    "1. The inner dimensions must match\n",
    "2. The resulting matrix has te shape of the inner dimensions\n",
    "\n",
    "You can perform matrix multplication using:\n",
    "- `tf.matmul()`\n",
    "- `tf.tensordot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication in tensorflow\n",
    "print(tensor)\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication with python operator \"@\"\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor (3, 2)\n",
    "X = tf.constant([[1, 2],\n",
    "                 [3, 4],\n",
    "                 [5, 6]])\n",
    "Y = tf.constant([[9, 8],\n",
    "                 [7, 6],\n",
    "                 [5, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìñ **Resource:** Infor and example of matrix multiplication: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "\n",
    "- The number of columns of the 1st matrix must equal the number of rows of the 2nd matrix.\n",
    "- And the result will have the same number of rows as the 1st matrix, and the same number of columns as the 2nd matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[9, 8, 7],\n",
       "       [6, 5, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets change the shape of Y\n",
    "tf.reshape(Y, shape=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 2]), TensorShape([2, 3]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, tf.reshape(Y, shape=(2,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[21, 18, 15],\n",
       "       [51, 44, 37],\n",
       "       [81, 70, 59]], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to matrix multiply X by reshaped Y\n",
    "X @ tf.reshape(Y, shape=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can do the same with transpose (switch the axies)\n",
    "X, tf.transpose(X), tf.reshape(X, shape=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, when performing matrix multiplication on two tensros and of the axes does not line up, you will transponse one of the tensors in order to satisfy the matrix multiplication rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaging the datatype of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float32, tf.int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor with default dtype (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "C = tf.constant([7, 10])\n",
    "B.dtype, C.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from float32 to float16 (reduced precission)\n",
    "D = tf.cast(B, tf.float16)\n",
    "D.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from int32 to float32\n",
    "E = tf.cast(C, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregatin tensors\n",
    "\n",
    "Aggregatin tensors = condensing them from multiple values down to a smaller amount of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values\n",
    "D = tf.constant([-7, -10])\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go trough the following forms of aggregation:\n",
    "- Get the minimum\n",
    "- Get the maximum\n",
    "- Get the mean\n",
    "- Get the sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([41, 66, 38, 64, 72, 95,  7, 43, 65, 87, 16, 44, 35, 71, 19, 64, 77,\n",
       "       56, 24, 86, 83, 70, 85, 69, 48, 90, 63, 23, 43, 89, 47,  8, 83, 30,\n",
       "       87,  8, 61, 58, 44, 77, 84, 10, 49, 41, 33, 80, 22, 65, 20, 45])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with values between 0 and 100 of size 50\n",
    "E = tf.constant(np.random.randint(0, 100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum:  7\n",
      "Maximum:  95\n",
      "Mean:  53\n",
      "Sum:  2685\n"
     ]
    }
   ],
   "source": [
    "minimum = tf.reduce_min(E)\n",
    "maximum = tf.reduce_max(E)\n",
    "mean = tf.reduce_mean(E)\n",
    "sum = tf.reduce_sum(E)\n",
    "\n",
    "print(\"Minimum: \", minimum.numpy())\n",
    "print(\"Maximum: \", maximum.numpy())\n",
    "print(\"Mean: \", mean.numpy())\n",
    "print(\"Sum: \",sum.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ†Ô∏è **Excercise** Find the variance and standard deviation of our `E` tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  644.0\n",
      "Std devation:  25.38\n"
     ]
    }
   ],
   "source": [
    "# Change the dtype to float32\n",
    "\n",
    "F = tf.cast(E, tf.float16)\n",
    "\n",
    "variance = tf.math.reduce_variance(F)\n",
    "std_deviation = tf.math.reduce_std(F)\n",
    "\n",
    "print(\"Variance: \", variance.numpy())\n",
    "print(\"Std devation: \", std_deviation.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the positional maximun and minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor for finding positional minimum and maximum\n",
    "tf.random.set_seed(42)\n",
    "F = tf.random.uniform(shape=[50])\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the positional maximun\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on our largest value position\n",
    "F[tf.argmax(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=16>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the positional minimum\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.009463668>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on our minimum value position\n",
    "F[tf.argmin(F)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing a tensor (removing all single dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 1, 50])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor to get started\n",
    "tf.random.set_seed(42)\n",
    "G = tf.constant(tf.random.uniform(shape = [1, 1, 1, 1, 50]))\n",
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of indices\n",
    "colours = [0, 1, 2, 3] # red, green, blue, purple\n",
    "\n",
    "#One-hot encode our list of indices\n",
    "tf.one_hot(colours, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'love deep learning', b'also like to dance',\n",
       "        b'also like to dance', b'also like to dance'],\n",
       "       [b'also like to dance', b'love deep learning',\n",
       "        b'also like to dance', b'also like to dance'],\n",
       "       [b'also like to dance', b'also like to dance',\n",
       "        b'love deep learning', b'also like to dance'],\n",
       "       [b'also like to dance', b'also like to dance',\n",
       "        b'also like to dance', b'love deep learning']], dtype=object)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify custom values for one hot encoding\n",
    "tf.one_hot(colours, depth=4, on_value=\"love deep learning\", off_value=\"also like to dance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squaring, log, square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041],\n",
       "       [0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686],\n",
       "       [0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tf.random.set_seed(42)\n",
    "A = tf.constant(tf.random.uniform(shape=[3,5]))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squaring:  [[0.4416428  0.19448698 0.12452606 0.21574403 0.00113302]\n",
      " [0.46877623 0.54777384 0.7611594  0.05122361 0.04981684]\n",
      " [0.09634077 0.52176905 0.01773882 0.300374   0.33017528]]\n",
      "Natural log [[-0.40862694 -0.818695   -1.0416201  -0.7668313  -3.3914328 ]\n",
      " [-0.37881485 -0.3009464  -0.13645622 -1.4857773  -1.4997011 ]\n",
      " [-1.1699319  -0.32526514 -2.0159998  -0.6013634  -0.5540658 ]]\n",
      "Square:  [[0.81520677 0.6640834  0.59403914 0.6815296  0.18346775]\n",
      " [0.8274493  0.8603008  0.9340474  0.4757377  0.47243714]\n",
      " [0.55712485 0.8499034  0.36494818 0.74031335 0.7580296 ]]\n"
     ]
    }
   ],
   "source": [
    "square = tf.square(A)\n",
    "log = tf.math.log(A)\n",
    "square_root = tf.sqrt(A)\n",
    "\n",
    "print(\"Squaring: \", square.numpy())\n",
    "print(\"Natural log\", log.numpy())\n",
    "print(\"Square: \", square_root.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy\n",
    "\n",
    "TensorFlow interacts beatifuly with NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor directly from a NumPy array\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our tensor back to a NumPy array\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default types of each are slightly different\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.]))\n",
    "tensor_J = tf.constant([3., 7., 10.])\n",
    "numpy_J.dtype, tensor_J.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find access to GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîëNote:** If you hace acces to a CUDA-enable GPU, TensorFlow will automatically use it whenver possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏èExcercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       " array([[[1, 2],\n",
       "         [3, 4]],\n",
       " \n",
       "        [[5, 6],\n",
       "         [7, 8]]], dtype=int32)>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector, scalar, matrix and tensor with values of your choosing using tf.constant()\n",
    "scalar = tf.constant(1)\n",
    "vector = tf.constant([1,2])\n",
    "matrix = tf.constant([[1,2],\n",
    "                      [3,4]])\n",
    "tensor = tf.constant([[[1,2],\n",
    "                       [3,4]],\n",
    "                       [[5,6],\n",
    "                        [7,8]]])\n",
    "scalar, vector, matrix, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2, 2]), 3, 8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape, rank and size of the tensors you created in 1.\n",
    "tensor.shape, tensor.ndim, tf.size(tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 300), dtype=float32, numpy=\n",
       " array([[0.6645621 , 0.44100678, 0.3528825 , ..., 0.31410468, 0.7593535 ,\n",
       "         0.03699052],\n",
       "        [0.532024  , 0.29129946, 0.10571766, ..., 0.54052293, 0.31425726,\n",
       "         0.2200619 ],\n",
       "        [0.08404207, 0.03614604, 0.97732127, ..., 0.21516645, 0.9786098 ,\n",
       "         0.00726748],\n",
       "        [0.7396945 , 0.6653172 , 0.0787828 , ..., 0.7117733 , 0.07013571,\n",
       "         0.9409125 ],\n",
       "        [0.15861344, 0.12024033, 0.27218235, ..., 0.8824879 , 0.1432488 ,\n",
       "         0.44135118]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 300), dtype=float32, numpy=\n",
       " array([[0.68789124, 0.48447883, 0.9309944 , ..., 0.6920762 , 0.33180213,\n",
       "         0.9212563 ],\n",
       "        [0.27369928, 0.10631859, 0.6218617 , ..., 0.4382149 , 0.30427706,\n",
       "         0.51477313],\n",
       "        [0.00920248, 0.37280262, 0.8177401 , ..., 0.56786287, 0.49201214,\n",
       "         0.9892651 ],\n",
       "        [0.88608265, 0.08672249, 0.12160683, ..., 0.91770685, 0.72545695,\n",
       "         0.8280058 ],\n",
       "        [0.36690474, 0.9200133 , 0.9646884 , ..., 0.69012   , 0.7137332 ,\n",
       "         0.2584542 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two tensors containing random values between 0 and 1 with shape [5, 300].\n",
    "tf.random.set_seed(42)\n",
    "random_tensor1 = tf.constant(tf.random.uniform(shape=[5,300], minval=0, maxval=1))\n",
    "random_tensor2 = tf.constant(tf.random.uniform(shape=[5,300], minval=0, maxval=1))\n",
    "random_tensor1, random_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 300), dtype=float32, numpy=\n",
       "array([[1.317161  , 0.61993605, 1.2612379 , ..., 1.5290778 , 1.0735596 ,\n",
       "        1.6227092 ],\n",
       "       [1.0170685 , 0.42642498, 0.8181824 , ..., 1.1469344 , 0.8212255 ,\n",
       "        1.1739546 ],\n",
       "       [0.45034647, 0.8037954 , 1.4656199 , ..., 1.105671  , 0.88152766,\n",
       "        1.481925  ],\n",
       "       ...,\n",
       "       [1.3204696 , 1.1634867 , 1.7423928 , ..., 1.8386563 , 1.5207756 ,\n",
       "        1.5979093 ],\n",
       "       [0.73207504, 0.90400356, 1.8493464 , ..., 1.3821819 , 0.98218614,\n",
       "        1.924531  ],\n",
       "       [1.0814031 , 0.5316744 , 0.7174167 , ..., 1.2942287 , 1.0804075 ,\n",
       "        1.0476992 ]], dtype=float32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply the two tensors you created in 3 using matrix multiplication.\n",
    "tf.matmul(tf.transpose(random_tensor1), random_tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 300), dtype=float32, numpy=\n",
       "array([[1.317161  , 0.61993605, 1.2612379 , ..., 1.5290778 , 1.0735596 ,\n",
       "        1.6227092 ],\n",
       "       [1.0170685 , 0.42642498, 0.8181824 , ..., 1.1469344 , 0.8212255 ,\n",
       "        1.1739546 ],\n",
       "       [0.45034647, 0.8037954 , 1.4656199 , ..., 1.105671  , 0.88152766,\n",
       "        1.481925  ],\n",
       "       ...,\n",
       "       [1.3204696 , 1.1634867 , 1.7423928 , ..., 1.8386563 , 1.5207756 ,\n",
       "        1.5979093 ],\n",
       "       [0.73207504, 0.90400356, 1.8493464 , ..., 1.3821819 , 0.98218614,\n",
       "        1.924531  ],\n",
       "       [1.0814031 , 0.5316744 , 0.7174167 , ..., 1.2942287 , 1.0804075 ,\n",
       "        1.0476992 ]], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply the two tensors you created in 3 using dot product.\n",
    "tf.tensordot(tf.transpose(random_tensor1), random_tensor2, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
       "array([[[0.7413678 , 0.62854624, 0.01738465],\n",
       "        [0.3431449 , 0.51063764, 0.3777541 ],\n",
       "        [0.07321596, 0.02137029, 0.2871771 ],\n",
       "        ...,\n",
       "        [0.98953485, 0.45382905, 0.2006687 ],\n",
       "        [0.6295223 , 0.4937899 , 0.01816809],\n",
       "        [0.95386636, 0.11542463, 0.85691285]],\n",
       "\n",
       "       [[0.78435016, 0.7826872 , 0.87936425],\n",
       "        [0.24906898, 0.3207239 , 0.10955775],\n",
       "        [0.543224  , 0.7151396 , 0.40334642],\n",
       "        ...,\n",
       "        [0.2445668 , 0.01746976, 0.9036933 ],\n",
       "        [0.02975535, 0.592268  , 0.9877522 ],\n",
       "        [0.36701274, 0.33112562, 0.5638567 ]],\n",
       "\n",
       "       [[0.15829337, 0.7288823 , 0.3366307 ],\n",
       "        [0.70792687, 0.16910625, 0.9429966 ],\n",
       "        [0.10120225, 0.5919596 , 0.8687303 ],\n",
       "        ...,\n",
       "        [0.28134012, 0.10011208, 0.37038183],\n",
       "        [0.77874243, 0.05421627, 0.4664607 ],\n",
       "        [0.2549187 , 0.7968637 , 0.83405185]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.32922816, 0.06343532, 0.23936498],\n",
       "        [0.42692196, 0.3615111 , 0.901929  ],\n",
       "        [0.8320831 , 0.21068895, 0.08272386],\n",
       "        ...,\n",
       "        [0.65110314, 0.40780962, 0.25967455],\n",
       "        [0.9018173 , 0.8245677 , 0.16757596],\n",
       "        [0.41854453, 0.19092035, 0.2523303 ]],\n",
       "\n",
       "       [[0.7064005 , 0.222404  , 0.82219553],\n",
       "        [0.8235872 , 0.76544905, 0.80999327],\n",
       "        [0.1100682 , 0.00520217, 0.6127168 ],\n",
       "        ...,\n",
       "        [0.98068535, 0.8958733 , 0.17706168],\n",
       "        [0.4252876 , 0.02087164, 0.496238  ],\n",
       "        [0.6599953 , 0.58505726, 0.7089884 ]],\n",
       "\n",
       "       [[0.90045786, 0.45803344, 0.9050728 ],\n",
       "        [0.92233   , 0.38456154, 0.30329156],\n",
       "        [0.03238845, 0.18773472, 0.9096625 ],\n",
       "        ...,\n",
       "        [0.4445815 , 0.04578841, 0.21090853],\n",
       "        [0.25966525, 0.24412918, 0.76123405],\n",
       "        [0.9643831 , 0.32687283, 0.4828869 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with random values between 0 and 1 with shape [224, 224, 3].\n",
    "random_tensor3 = tf.constant(tf.random.uniform(shape=[224, 224, 3], minval=0, maxval=1))\n",
    "random_tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max values:  tf.Tensor(\n",
      "[[0.99845374 0.99930906 0.99262166]\n",
      " [0.99466574 0.99434555 0.9957906 ]\n",
      " [0.9993377  0.9988344  0.99788725]\n",
      " [0.9930023  0.99388456 0.9973532 ]\n",
      " [0.99890304 0.99934196 0.999063  ]\n",
      " [0.99909663 0.9912498  0.9989666 ]\n",
      " [0.9984517  0.9993125  0.9972266 ]\n",
      " [0.9851161  0.9997518  0.9938358 ]\n",
      " [0.99558496 0.9875896  0.99800336]\n",
      " [0.99865353 0.9981276  0.99659836]\n",
      " [0.99160516 0.99429524 0.99986553]\n",
      " [0.99120665 0.9974369  0.9837067 ]\n",
      " [0.9998193  0.9986278  0.9997519 ]\n",
      " [0.9990151  0.9997431  0.99959373]\n",
      " [0.99833953 0.99908006 0.9974154 ]\n",
      " [0.9997325  0.9948616  0.99942064]\n",
      " [0.9960431  0.99533176 0.99374545]\n",
      " [0.99750674 0.9957348  0.99729204]\n",
      " [0.9953059  0.99919796 0.99888754]\n",
      " [0.99667954 0.9962187  0.99953544]\n",
      " [0.9983853  0.9915079  0.99962735]\n",
      " [0.9898201  0.99667823 0.99680734]\n",
      " [0.99451494 0.9982387  0.9974679 ]\n",
      " [0.99928916 0.99623907 0.9949752 ]\n",
      " [0.99431205 0.99085116 0.9984652 ]\n",
      " [0.9947418  0.99655926 0.99838555]\n",
      " [0.9961513  0.99756706 0.99831486]\n",
      " [0.99408686 0.99626756 0.9995775 ]\n",
      " [0.99727106 0.9978094  0.9874866 ]\n",
      " [0.99634314 0.9921826  0.99808526]\n",
      " [0.9964644  0.99127257 0.98901904]\n",
      " [0.9985864  0.9894761  0.9985472 ]\n",
      " [0.9973928  0.9987302  0.98841095]\n",
      " [0.99437606 0.9983698  0.9973351 ]\n",
      " [0.9954928  0.9996017  0.99777126]\n",
      " [0.9840361  0.99596083 0.9972894 ]\n",
      " [0.99978673 0.9843577  0.99390256]\n",
      " [0.9986249  0.9794526  0.9955791 ]\n",
      " [0.9995458  0.99456394 0.9946526 ]\n",
      " [0.9991182  0.9961295  0.9953816 ]\n",
      " [0.99541664 0.99530363 0.99985814]\n",
      " [0.99263835 0.999109   0.9969249 ]\n",
      " [0.9991859  0.99065435 0.9914136 ]\n",
      " [0.9906702  0.99452376 0.9996517 ]\n",
      " [0.9975053  0.9897255  0.9887798 ]\n",
      " [0.98918223 0.9960978  0.99724174]\n",
      " [0.9943588  0.99851537 0.99697995]\n",
      " [0.9967083  0.9982369  0.997609  ]\n",
      " [0.9994606  0.99846065 0.99079216]\n",
      " [0.9987831  0.997278   0.987236  ]\n",
      " [0.99959457 0.99533796 0.99766517]\n",
      " [0.9996768  0.9908546  0.9958056 ]\n",
      " [0.9995378  0.9937458  0.9895203 ]\n",
      " [0.9995246  0.98839176 0.99309456]\n",
      " [0.996156   0.9999633  0.99291325]\n",
      " [0.98664284 0.9909704  0.9921967 ]\n",
      " [0.9984081  0.9997122  0.9923812 ]\n",
      " [0.9954152  0.99256027 0.9987396 ]\n",
      " [0.98873234 0.9999918  0.99861574]\n",
      " [0.99961996 0.9944428  0.988245  ]\n",
      " [0.9999813  0.9896165  0.99895644]\n",
      " [0.9984187  0.993991   0.9873296 ]\n",
      " [0.9995934  0.999403   0.9984983 ]\n",
      " [0.9975642  0.99994886 0.9953469 ]\n",
      " [0.9973607  0.99998367 0.99608755]\n",
      " [0.99653447 0.9945427  0.9993334 ]\n",
      " [0.999442   0.9982531  0.9984993 ]\n",
      " [0.9896691  0.9993751  0.99601614]\n",
      " [0.9977627  0.9980459  0.9989507 ]\n",
      " [0.9988378  0.99818516 0.9969574 ]\n",
      " [0.9970051  0.98135674 0.9989995 ]\n",
      " [0.9956008  0.9917606  0.9979981 ]\n",
      " [0.9976326  0.9963504  0.996541  ]\n",
      " [0.99753976 0.99978006 0.9881561 ]\n",
      " [0.99982166 0.9932102  0.99769175]\n",
      " [0.99821615 0.99675095 0.9987265 ]\n",
      " [0.9968225  0.99175334 0.9970671 ]\n",
      " [0.9992144  0.9929007  0.9995568 ]\n",
      " [0.99542606 0.9955307  0.9950546 ]\n",
      " [0.9912801  0.9920186  0.99956656]\n",
      " [0.99543405 0.997826   0.99751556]\n",
      " [0.99896955 0.99907005 0.9950589 ]\n",
      " [0.9938457  0.9924774  0.9877428 ]\n",
      " [0.99976754 0.99726427 0.99843144]\n",
      " [0.9922346  0.9969646  0.9881915 ]\n",
      " [0.9937842  0.9972644  0.9998956 ]\n",
      " [0.99693096 0.99574876 0.99912345]\n",
      " [0.9993086  0.99804485 0.9992548 ]\n",
      " [0.9941571  0.99510634 0.9946796 ]\n",
      " [0.9945396  0.99862957 0.9913138 ]\n",
      " [0.9989486  0.9986596  0.9986067 ]\n",
      " [0.986789   0.99811435 0.99629354]\n",
      " [0.9989364  0.9997182  0.9935856 ]\n",
      " [0.99844515 0.9904369  0.99422824]\n",
      " [0.9975085  0.9815272  0.9923638 ]\n",
      " [0.99994373 0.99456024 0.9711864 ]\n",
      " [0.98979545 0.9959949  0.9955597 ]\n",
      " [0.99104965 0.9973923  0.99806154]\n",
      " [0.99176776 0.99783957 0.9935384 ]\n",
      " [0.9991542  0.9995054  0.9986594 ]\n",
      " [0.9993583  0.9997277  0.99733853]\n",
      " [0.9923755  0.9999565  0.9982939 ]\n",
      " [0.99940395 0.9925839  0.9935405 ]\n",
      " [0.99648416 0.99523413 0.99860036]\n",
      " [0.99767065 0.9898715  0.99171114]\n",
      " [0.990672   0.99445784 0.99540615]\n",
      " [0.9997612  0.988111   0.99611986]\n",
      " [0.9969163  0.9981903  0.9816766 ]\n",
      " [0.9918184  0.99933934 0.99705124]\n",
      " [0.99425507 0.996145   0.983436  ]\n",
      " [0.9985815  0.998348   0.99590385]\n",
      " [0.992785   0.99797094 0.99329996]\n",
      " [0.99191403 0.9929569  0.999544  ]\n",
      " [0.9920981  0.9982209  0.9972125 ]\n",
      " [0.9937252  0.976534   0.9985924 ]\n",
      " [0.99809015 0.9988475  0.9993112 ]\n",
      " [0.99380183 0.99764264 0.9950968 ]\n",
      " [0.9922925  0.9976479  0.99740744]\n",
      " [0.9970808  0.9934089  0.9996041 ]\n",
      " [0.99001837 0.99824405 0.9996246 ]\n",
      " [0.9972919  0.9996153  0.99104655]\n",
      " [0.99976707 0.99481034 0.99427116]\n",
      " [0.9981848  0.9992788  0.99683976]\n",
      " [0.9877726  0.9963125  0.9961529 ]\n",
      " [0.99979734 0.9868486  0.99988794]\n",
      " [0.99378014 0.9875746  0.9965    ]\n",
      " [0.9991933  0.9995012  0.9985533 ]\n",
      " [0.9789599  0.9967655  0.9953743 ]\n",
      " [0.99894893 0.9932231  0.996881  ]\n",
      " [0.9859452  0.99585104 0.9945197 ]\n",
      " [0.9956863  0.98131907 0.9989102 ]\n",
      " [0.99313366 0.999333   0.9984505 ]\n",
      " [0.99984443 0.995026   0.9985832 ]\n",
      " [0.99807906 0.99322903 0.99854994]\n",
      " [0.97891176 0.9948453  0.98883545]\n",
      " [0.9987898  0.9978037  0.999081  ]\n",
      " [0.9970453  0.9867351  0.99888015]\n",
      " [0.9949591  0.9995016  0.99157906]\n",
      " [0.99813557 0.9934578  0.99707806]\n",
      " [0.9887134  0.99530876 0.9906883 ]\n",
      " [0.9998046  0.99942315 0.99975836]\n",
      " [0.9979677  0.9975052  0.9999776 ]\n",
      " [0.9999778  0.99488246 0.997661  ]\n",
      " [0.99275684 0.99993813 0.9913701 ]\n",
      " [0.99626017 0.9990027  0.99823654]\n",
      " [0.9963701  0.9957473  0.9917549 ]\n",
      " [0.99672043 0.9957856  0.99390566]\n",
      " [0.9960207  0.9996743  0.9989439 ]\n",
      " [0.9993167  0.99104536 0.998296  ]\n",
      " [0.99649525 0.99682474 0.9954903 ]\n",
      " [0.99623704 0.99972606 0.982044  ]\n",
      " [0.9953575  0.99743235 0.99541306]\n",
      " [0.9937023  0.99967074 0.99557424]\n",
      " [0.9903748  0.9969835  0.9999696 ]\n",
      " [0.99955475 0.9985409  0.99353635]\n",
      " [0.99534845 0.9961895  0.99907935]\n",
      " [0.9991518  0.9878471  0.9969382 ]\n",
      " [0.9981859  0.9993571  0.9950347 ]\n",
      " [0.9946494  0.99151003 0.9954426 ]\n",
      " [0.99834955 0.9994116  0.9969311 ]\n",
      " [0.99342704 0.99901116 0.9950397 ]\n",
      " [0.9958389  0.99755883 0.9965949 ]\n",
      " [0.9910518  0.99429166 0.9937006 ]\n",
      " [0.99318564 0.99626637 0.9909122 ]\n",
      " [0.9969504  0.9995512  0.9927335 ]\n",
      " [0.99350166 0.99825716 0.99512136]\n",
      " [0.99385047 0.99633026 0.988605  ]\n",
      " [0.9947401  0.9994103  0.9984137 ]\n",
      " [0.9988979  0.9962628  0.988258  ]\n",
      " [0.9974605  0.9941627  0.9996201 ]\n",
      " [0.99603176 0.999653   0.99351084]\n",
      " [0.9949826  0.99009144 0.9872658 ]\n",
      " [0.99648154 0.9907197  0.9891151 ]\n",
      " [0.9922403  0.98299015 0.9996239 ]\n",
      " [0.99772525 0.99938893 0.99636126]\n",
      " [0.99716914 0.9977088  0.9889859 ]\n",
      " [0.99845135 0.9934511  0.99096704]\n",
      " [0.9931505  0.9987241  0.99772716]\n",
      " [0.9976144  0.9947636  0.9921236 ]\n",
      " [0.9916476  0.98612094 0.9861163 ]\n",
      " [0.9959618  0.993968   0.99612   ]\n",
      " [0.9948534  0.9978998  0.99381113]\n",
      " [0.99554586 0.9999758  0.98724246]\n",
      " [0.99526    0.9965458  0.99523306]\n",
      " [0.99893606 0.9995725  0.9637047 ]\n",
      " [0.9996016  0.9939934  0.99906206]\n",
      " [0.99498045 0.9996003  0.9912348 ]\n",
      " [0.9999355  0.9930407  0.99241006]\n",
      " [0.99889994 0.99980307 0.9970739 ]\n",
      " [0.9966061  0.99821866 0.99702716]\n",
      " [0.9993744  0.9981735  0.99704874]\n",
      " [0.99622035 0.98396575 0.9986981 ]\n",
      " [0.99479496 0.9976603  0.98908913]\n",
      " [0.9896605  0.9883368  0.99734986]\n",
      " [0.9965801  0.99859524 0.9994631 ]\n",
      " [0.9929483  0.99824667 0.9972844 ]\n",
      " [0.9988158  0.9944594  0.9974779 ]\n",
      " [0.9900675  0.98776937 0.9794773 ]\n",
      " [0.9920641  0.9933765  0.99284697]\n",
      " [0.97483206 0.9896858  0.99785244]\n",
      " [0.99169624 0.99616754 0.99581194]\n",
      " [0.995168   0.9992075  0.9958538 ]\n",
      " [0.9823456  0.99882615 0.99941003]\n",
      " [0.9962709  0.9976268  0.9993137 ]\n",
      " [0.999177   0.9978261  0.9963287 ]\n",
      " [0.9993247  0.9994161  0.9961573 ]\n",
      " [0.9955872  0.99744296 0.985942  ]\n",
      " [0.99905825 0.9956869  0.97578764]\n",
      " [0.9917282  0.9934075  0.99499476]\n",
      " [0.9978045  0.9988322  0.9970828 ]\n",
      " [0.99708235 0.98827505 0.99435806]\n",
      " [0.9978682  0.9953898  0.99409115]\n",
      " [0.99955773 0.99519396 0.9965714 ]\n",
      " [0.9985641  0.9922924  0.99848807]\n",
      " [0.9997562  0.9976785  0.9992213 ]\n",
      " [0.99955356 0.9928005  0.9997659 ]\n",
      " [0.999061   0.9985033  0.9969462 ]\n",
      " [0.9990126  0.99750376 0.997612  ]\n",
      " [0.9974495  0.99788094 0.9966214 ]\n",
      " [0.9992498  0.99883103 0.9920347 ]\n",
      " [0.9967823  0.9995347  0.9976599 ]\n",
      " [0.99361277 0.99625194 0.9966253 ]\n",
      " [0.9970275  0.99856126 0.9946816 ]\n",
      " [0.9994445  0.99884284 0.991447  ]], shape=(224, 3), dtype=float32)\n",
      "Min values tf.Tensor(\n",
      "[[2.67446041e-03 2.14838982e-03 1.05965137e-03]\n",
      " [5.47564030e-03 2.21121311e-03 4.15408611e-03]\n",
      " [3.72385979e-03 5.20217419e-03 9.02771950e-04]\n",
      " [1.11603737e-03 6.35766983e-03 3.18384171e-03]\n",
      " [2.10273266e-03 5.84840775e-04 1.05011463e-03]\n",
      " [4.26018238e-03 1.58730745e-02 1.21641159e-03]\n",
      " [6.51884079e-03 1.17063522e-03 2.71463394e-03]\n",
      " [5.67364693e-03 8.54074955e-03 1.52909756e-02]\n",
      " [7.19797611e-03 8.43882561e-04 1.91795826e-03]\n",
      " [4.71234322e-04 6.39832020e-03 2.17664242e-03]\n",
      " [2.41947174e-03 5.75447083e-03 1.54391527e-02]\n",
      " [9.96232033e-04 1.06847286e-03 1.08550787e-02]\n",
      " [7.00187683e-03 3.46624851e-03 2.44665146e-03]\n",
      " [1.11377239e-03 7.05718994e-05 2.76803970e-03]\n",
      " [3.22699547e-03 9.34267044e-03 4.85146046e-03]\n",
      " [2.55906582e-03 3.21245193e-03 2.09597349e-02]\n",
      " [4.42552567e-03 6.46495819e-03 1.56283379e-03]\n",
      " [1.74760818e-04 8.91327858e-04 7.24554062e-03]\n",
      " [6.97255135e-04 5.13529778e-03 2.70259380e-03]\n",
      " [6.96301460e-04 1.15126371e-02 1.75446272e-02]\n",
      " [1.21183395e-02 1.34944916e-03 3.73733044e-03]\n",
      " [2.35307217e-03 1.35254860e-03 3.71372700e-03]\n",
      " [1.06908083e-02 1.62684917e-03 5.34749031e-03]\n",
      " [2.34341621e-03 3.37314606e-03 1.15585327e-03]\n",
      " [2.34997272e-03 6.55043125e-03 1.56080723e-03]\n",
      " [1.43407583e-02 5.88893890e-05 3.34930420e-03]\n",
      " [6.97970390e-03 8.14437866e-04 3.18539143e-03]\n",
      " [2.90274620e-03 5.66852093e-03 2.88796425e-03]\n",
      " [5.81216812e-03 2.59160995e-04 2.24125385e-03]\n",
      " [2.09927559e-03 2.30789185e-04 1.93405151e-03]\n",
      " [9.49025154e-04 1.23238564e-03 2.39002705e-03]\n",
      " [7.75778294e-03 1.85263157e-03 4.09388542e-03]\n",
      " [4.92572784e-04 9.56296921e-04 3.77678871e-03]\n",
      " [1.65581703e-03 1.10888481e-03 8.71896744e-04]\n",
      " [3.63492966e-03 2.70855427e-03 4.44495678e-03]\n",
      " [1.47342682e-04 5.44428825e-04 8.76605511e-03]\n",
      " [7.17759132e-03 9.60123539e-03 1.71692371e-02]\n",
      " [5.79750538e-03 4.69088554e-04 1.26063824e-03]\n",
      " [2.20596790e-03 6.04259968e-03 5.84363937e-04]\n",
      " [1.55568123e-03 3.22818756e-03 9.23848152e-03]\n",
      " [8.91160965e-03 5.44500351e-03 1.29337311e-02]\n",
      " [4.36019897e-03 2.96604633e-03 5.83374500e-03]\n",
      " [8.36467743e-03 2.80857086e-04 5.78927994e-03]\n",
      " [6.96837902e-03 2.01308727e-03 1.36235952e-02]\n",
      " [5.77437878e-03 8.38220119e-03 1.27208233e-03]\n",
      " [1.09267235e-03 6.71052933e-03 3.95452976e-03]\n",
      " [7.77006149e-04 3.15213203e-03 4.13119793e-03]\n",
      " [6.47675991e-03 8.89062881e-04 1.24269724e-02]\n",
      " [4.44650650e-03 4.18877602e-03 2.31397152e-03]\n",
      " [6.82342052e-03 1.01327896e-03 1.64389610e-03]\n",
      " [1.06036663e-03 6.64472580e-04 1.57248974e-03]\n",
      " [2.57611275e-04 4.67598438e-03 1.30665302e-03]\n",
      " [8.89301300e-04 6.95943832e-03 2.74193287e-03]\n",
      " [7.72356987e-04 6.64949417e-04 2.14612484e-03]\n",
      " [8.36491585e-04 1.91324949e-02 1.49726868e-03]\n",
      " [3.03912163e-03 2.97713280e-03 1.32095814e-02]\n",
      " [2.23839283e-03 1.10685825e-03 6.43730164e-04]\n",
      " [6.89935684e-03 1.38878822e-03 6.58547878e-03]\n",
      " [2.86698341e-03 3.27777863e-03 2.22957134e-03]\n",
      " [3.66258621e-03 4.66775894e-03 3.15856934e-03]\n",
      " [4.59432602e-03 1.89495087e-03 3.32355499e-03]\n",
      " [4.84859943e-03 4.58478928e-04 5.15949726e-03]\n",
      " [6.46424294e-03 4.74750996e-03 6.48760796e-03]\n",
      " [9.57190990e-03 2.26974487e-03 5.25486469e-03]\n",
      " [2.71642208e-03 3.38733196e-03 2.75254250e-03]\n",
      " [3.19898129e-03 1.74939632e-03 8.20040703e-04]\n",
      " [2.67708302e-03 1.39939785e-03 4.85157967e-03]\n",
      " [3.98027897e-03 1.34527683e-03 3.30317020e-03]\n",
      " [7.91192055e-03 7.65275955e-03 9.01818275e-03]\n",
      " [2.79998779e-03 3.09896469e-03 1.40535831e-03]\n",
      " [3.52119207e-02 4.05311584e-06 5.11169434e-03]\n",
      " [4.50015068e-03 1.81233883e-03 6.10733032e-03]\n",
      " [1.24347210e-03 1.10936165e-03 3.00788879e-03]\n",
      " [3.85963917e-03 3.21877003e-03 2.25245953e-03]\n",
      " [2.97937393e-02 1.84963942e-02 4.73785400e-03]\n",
      " [1.14896297e-02 2.09009647e-03 2.11572647e-03]\n",
      " [2.27999687e-03 1.88016891e-03 2.78091431e-03]\n",
      " [6.11388683e-03 5.91874123e-04 1.23977661e-04]\n",
      " [3.33428383e-04 7.77959824e-04 4.23836708e-03]\n",
      " [9.95922089e-03 1.98233128e-03 2.68340111e-04]\n",
      " [1.39617920e-03 1.35613680e-02 8.93509388e-03]\n",
      " [3.40461731e-03 2.01821327e-04 7.45534897e-03]\n",
      " [6.60490990e-03 5.24938107e-03 2.03943253e-03]\n",
      " [5.26690483e-03 1.57070160e-03 8.08572769e-03]\n",
      " [3.40461731e-04 4.34172153e-03 7.90810585e-03]\n",
      " [2.23064423e-03 1.88791752e-03 5.23710251e-03]\n",
      " [1.85906887e-03 9.91106033e-03 3.78286839e-03]\n",
      " [8.42690468e-03 1.06985569e-02 2.67732143e-03]\n",
      " [1.13210678e-02 2.26855278e-04 6.19280338e-03]\n",
      " [1.99794769e-03 8.67319107e-03 1.36413574e-02]\n",
      " [1.25052929e-02 1.13725662e-04 1.26099586e-03]\n",
      " [6.31105900e-03 2.91252136e-03 1.65724754e-03]\n",
      " [9.09161568e-03 2.24590302e-03 3.55303288e-03]\n",
      " [2.05278397e-03 5.26309013e-04 2.34293938e-03]\n",
      " [1.51240826e-03 2.27189064e-03 3.74162197e-03]\n",
      " [6.31892681e-03 3.12268734e-03 2.85530090e-03]\n",
      " [8.32402706e-03 3.08668613e-03 2.14576721e-05]\n",
      " [2.61294842e-03 2.36034393e-05 1.31090879e-02]\n",
      " [3.03649902e-03 5.84244728e-04 4.89830971e-04]\n",
      " [9.70363617e-04 1.29282475e-03 5.99622726e-05]\n",
      " [2.40743160e-03 6.87015057e-03 1.37351751e-02]\n",
      " [3.59189510e-03 5.67305088e-03 2.03621387e-03]\n",
      " [5.02717495e-03 4.54878807e-03 1.80172920e-03]\n",
      " [1.04178190e-02 5.63859940e-04 2.55405903e-03]\n",
      " [7.10594654e-03 1.69265270e-03 1.17418766e-02]\n",
      " [1.06832981e-02 1.20782852e-03 1.00317001e-02]\n",
      " [2.95400620e-04 2.42483616e-03 1.76954269e-03]\n",
      " [2.81536579e-03 3.68356705e-04 5.10013103e-03]\n",
      " [3.79216671e-03 1.72877312e-03 4.79519367e-03]\n",
      " [7.00831413e-04 4.33909893e-03 1.63090229e-02]\n",
      " [9.45806503e-04 6.33239746e-03 2.74944305e-03]\n",
      " [4.89389896e-03 4.48477268e-03 1.47454739e-02]\n",
      " [8.99100304e-03 2.46000290e-03 3.84163857e-03]\n",
      " [2.79855728e-03 2.73203850e-03 3.49652767e-03]\n",
      " [1.35266781e-03 3.06129456e-04 2.66301632e-03]\n",
      " [2.69782543e-03 2.23660469e-03 2.56097317e-03]\n",
      " [1.26576424e-03 2.43461132e-03 3.74078751e-04]\n",
      " [5.79655170e-03 1.38449669e-03 4.63724136e-04]\n",
      " [1.08083487e-02 5.27501106e-04 6.14428520e-03]\n",
      " [1.17242336e-03 9.29474831e-04 3.69632244e-03]\n",
      " [7.64966011e-04 9.47093964e-03 5.87892532e-03]\n",
      " [9.55760479e-03 3.22461128e-04 8.41963291e-03]\n",
      " [1.42312050e-03 2.19857693e-03 6.93082809e-04]\n",
      " [4.76241112e-04 4.60505486e-04 4.45055962e-03]\n",
      " [5.20133972e-03 7.31039047e-03 1.31424665e-02]\n",
      " [6.30974770e-04 6.08813763e-03 8.40902328e-04]\n",
      " [1.68502331e-03 3.65996361e-03 7.21693039e-04]\n",
      " [3.14176083e-03 1.35171413e-03 1.72604322e-02]\n",
      " [1.13952160e-03 1.08766556e-03 2.08854675e-03]\n",
      " [8.16583633e-03 2.05707550e-03 5.65218925e-03]\n",
      " [5.12433052e-03 2.74574757e-03 6.39081001e-03]\n",
      " [1.20600462e-02 7.45868683e-03 2.94506550e-03]\n",
      " [1.24073029e-03 3.75509262e-04 1.32579803e-02]\n",
      " [4.90331650e-03 2.39908695e-03 6.16645813e-03]\n",
      " [1.15740299e-03 5.91003895e-03 1.57802105e-02]\n",
      " [8.35359097e-03 2.30193138e-04 1.42168999e-03]\n",
      " [5.94854355e-03 3.70121002e-03 8.93259048e-03]\n",
      " [5.03897667e-04 5.86748123e-04 2.77614594e-03]\n",
      " [7.31503963e-03 2.86948681e-03 1.23095512e-03]\n",
      " [1.30534172e-04 5.16617298e-03 2.14412212e-02]\n",
      " [4.39572334e-03 3.85272503e-03 1.10950470e-02]\n",
      " [1.63710117e-03 2.40910053e-03 1.62100792e-03]\n",
      " [2.30922699e-02 1.39594078e-04 6.65736198e-03]\n",
      " [6.79004192e-03 1.43945217e-03 5.50186634e-03]\n",
      " [4.55975533e-04 4.69779968e-03 2.97427177e-03]\n",
      " [1.10237598e-02 1.78362131e-02 3.09622288e-03]\n",
      " [3.40390205e-03 4.50634956e-03 3.20327282e-03]\n",
      " [6.91151619e-03 3.67760658e-04 6.56068325e-03]\n",
      " [3.64780426e-04 8.57520103e-03 2.74419785e-04]\n",
      " [4.48822975e-04 2.01964378e-03 2.20048428e-03]\n",
      " [9.23991203e-04 1.03474855e-02 1.37901306e-03]\n",
      " [1.40655041e-03 4.85885143e-03 1.33919716e-03]\n",
      " [4.02259827e-03 1.39447451e-02 4.33206558e-04]\n",
      " [1.30522251e-02 5.27381897e-04 8.05854797e-05]\n",
      " [6.44350052e-03 1.13844872e-03 5.55717945e-03]\n",
      " [1.65212154e-03 7.64882565e-03 3.62396240e-03]\n",
      " [4.00543213e-04 5.25736809e-03 1.47690773e-02]\n",
      " [4.04691696e-03 5.15913963e-03 5.04493713e-04]\n",
      " [1.40118599e-03 1.51968002e-03 1.93536282e-03]\n",
      " [1.19214058e-02 1.70171261e-03 5.42283058e-04]\n",
      " [1.35878325e-02 5.10203838e-03 7.83395767e-03]\n",
      " [6.55746460e-03 2.58982182e-03 5.68473339e-03]\n",
      " [5.87081909e-03 5.36441803e-05 9.66787338e-05]\n",
      " [8.72159004e-03 1.04211569e-02 3.45945358e-04]\n",
      " [5.51605225e-03 3.05867195e-03 5.38325310e-03]\n",
      " [8.21113586e-03 8.70347023e-04 9.08732414e-04]\n",
      " [8.14318657e-04 1.25992298e-03 3.35204601e-03]\n",
      " [7.26342201e-04 6.23154640e-03 3.81159782e-03]\n",
      " [1.69491768e-03 2.02107430e-03 3.56483459e-03]\n",
      " [4.79602814e-03 5.17249107e-04 1.80149078e-03]\n",
      " [3.14712524e-05 6.72399998e-03 5.53131104e-04]\n",
      " [6.50525093e-04 4.27484512e-04 7.99536705e-04]\n",
      " [6.46424294e-03 1.86300278e-03 7.88450241e-03]\n",
      " [4.45580482e-03 9.25421715e-04 1.81329250e-03]\n",
      " [4.23824787e-03 3.61382961e-03 9.60302353e-03]\n",
      " [1.34366751e-02 3.77631187e-03 1.44839287e-02]\n",
      " [2.87878513e-03 1.56164169e-04 1.89675093e-02]\n",
      " [9.02795792e-03 1.94311142e-04 5.09762764e-03]\n",
      " [4.16636467e-04 1.28637552e-02 5.84089756e-03]\n",
      " [1.09429359e-02 3.41391563e-03 4.74452972e-04]\n",
      " [9.36579704e-03 1.56283379e-04 9.13131237e-03]\n",
      " [1.88720226e-03 4.54902649e-03 8.44597816e-04]\n",
      " [3.35454941e-04 1.52325630e-03 7.26473331e-03]\n",
      " [1.46639347e-03 3.92222404e-03 1.02258921e-02]\n",
      " [8.66031647e-03 2.41978168e-02 7.86638260e-03]\n",
      " [5.57124615e-03 5.27358055e-03 2.77888775e-03]\n",
      " [5.57100773e-03 3.35228443e-03 8.60810280e-04]\n",
      " [2.11000443e-04 5.33294678e-03 3.86190414e-03]\n",
      " [6.46257401e-03 5.24640083e-04 4.19938564e-03]\n",
      " [9.41038132e-03 1.18491650e-02 5.96606731e-03]\n",
      " [5.91123104e-03 6.49094582e-04 4.23610210e-03]\n",
      " [4.94515896e-03 3.58390808e-03 1.24957561e-02]\n",
      " [1.07383728e-03 1.94668770e-03 6.86645508e-04]\n",
      " [1.68502331e-03 9.44375992e-04 6.39152527e-03]\n",
      " [2.69067287e-03 5.28097153e-05 3.37982178e-03]\n",
      " [1.62087679e-02 1.55184269e-02 3.26633453e-03]\n",
      " [4.81665134e-03 1.42173767e-02 4.78518009e-03]\n",
      " [1.17695332e-03 1.34038925e-03 8.65530968e-03]\n",
      " [6.85811043e-04 5.63001633e-03 5.24818897e-03]\n",
      " [8.41951370e-03 2.67744064e-04 3.24261189e-03]\n",
      " [1.13165379e-02 6.60169125e-03 3.11636925e-03]\n",
      " [3.22914124e-03 5.22494316e-04 3.39126587e-03]\n",
      " [1.08218193e-03 5.42891026e-03 6.99937344e-03]\n",
      " [1.01716518e-02 2.01742649e-02 1.65936947e-02]\n",
      " [3.80086899e-03 8.89241695e-03 4.31442261e-03]\n",
      " [1.06060505e-03 1.68144703e-03 2.00390816e-03]\n",
      " [4.29272652e-04 4.93001938e-03 7.03668594e-03]\n",
      " [1.19411945e-03 6.44671917e-03 2.55346298e-03]\n",
      " [8.68368149e-03 6.68466091e-03 4.59897518e-03]\n",
      " [3.02791595e-03 2.57384777e-03 1.49726868e-04]\n",
      " [2.67159939e-03 5.44548035e-04 3.58617306e-03]\n",
      " [1.04653835e-03 9.36806202e-03 7.15804100e-03]\n",
      " [1.84965134e-03 1.60002708e-03 6.46615028e-03]\n",
      " [7.76398182e-03 1.13271475e-02 4.63020802e-03]\n",
      " [2.38418579e-07 1.45566463e-03 1.03521347e-03]\n",
      " [1.15990639e-02 1.17707253e-03 1.32203102e-03]\n",
      " [8.25285912e-04 2.70974636e-03 1.72877312e-03]\n",
      " [8.60297680e-03 1.16956234e-03 6.08301163e-03]\n",
      " [9.31227207e-03 7.15255737e-06 1.73664093e-02]\n",
      " [1.00798607e-02 8.41677189e-03 1.83725357e-03]\n",
      " [4.17780876e-03 6.03675842e-04 1.17433071e-03]\n",
      " [7.38739967e-04 4.43661213e-03 6.89625740e-04]\n",
      " [2.13229656e-03 3.95476818e-03 1.81680918e-02]\n",
      " [1.10626221e-04 7.02142715e-04 2.79068947e-03]], shape=(224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Find the min and max values of the tensor you created in 6 along the first axis.\n",
    "print(\"Max values: \", tf.reduce_max(random_tensor3, axis=0))\n",
    "print(\"Min values\", tf.reduce_min(random_tensor3, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([224, 224,   3], dtype=int32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Created a tensor with random values of shape [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3].\n",
    "random_tensor4 = tf.constant(tf.random.uniform(shape=[1, 224, 224, 3]))\n",
    "tf.shape(tf.squeeze(random_tensor4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=9>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=9>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with shape [10] using your own choice of values, then find the index which has the maximum value.\n",
    "values = [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "tensor_shape10 = tf.constant(values)\n",
    "tf.argmax(tensor_shape10) ,tensor_shape10[tf.argmax(tensor_shape10)], tf.argmin(tensor_shape10), tensor_shape10[tf.argmin(tensor_shape10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the tensor you created in 9.\n",
    "tf.one_hot(tensor_shape10, depth=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
